{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d90b7f",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4ef17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Lenguajes\\Python\\Python 3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Librerias basicas\n",
    "import os, tempfile, glob, random, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from uuid import uuid4\n",
    "from PIL import Image\n",
    "import chromadb\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from getpass import getpass\n",
    "\n",
    "# Para el entorno de google\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Langchain \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string, ChatMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter,LongContextReorder\n",
    "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts.base import format_document\n",
    "\n",
    "\n",
    "# Document Loaders\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    DirectoryLoader,\n",
    "    CSVLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    Docx2txtLoader,\n",
    "    JSONLoader\n",
    ")\n",
    "\n",
    "# Text Splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# Chroma: vectorstore\n",
    "from langchain_chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59208250",
   "metadata": {},
   "source": [
    "## Api key de google gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3de133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entorno de Langchain\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entorno de google / genai\n",
    "gemini_client = genai.Client(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40abca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentEmbedding(\n",
      "  values=[\n",
      "    -0.022374554,\n",
      "    -0.004560777,\n",
      "    0.013309286,\n",
      "    -0.0545072,\n",
      "    -0.02090443,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# test embedding\n",
    "result = gemini_client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=\"What is the meaning of life?\")\n",
    "\n",
    "print(result.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2590b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result.embeddings[0].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d36db",
   "metadata": {},
   "source": [
    "# Cargado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8cfbf",
   "metadata": {},
   "source": [
    "## Cargado del JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06b71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../resources/cpe.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f8a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 426 documentos desde el JSON.\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    tipo = item.get(\"tipo\", \"\").capitalize()\n",
    "    text = \"\"\n",
    "\n",
    "    if tipo == \"Introduccion\":\n",
    "        text = f\"Título: {item.get('titulo', '')}\\n\" \\\n",
    "                f\"Subtítulo: {item.get('subtitulo', '')}\\n\" \\\n",
    "                f\"{item.get('contenido', '')}\"\n",
    "\n",
    "    elif tipo == \"Articulo\":\n",
    "        text = (\n",
    "            f\"Parte {item.get('parte_num', '')}: {item.get('parte_nom', '')}\\n\"\n",
    "            f\"Título {item.get('titulo_num', '')}: {item.get('titulo_nom', '')}\\n\"\n",
    "            f\"Capítulo {item.get('capitulo_num', '')}: {item.get('capitulo_nom', '')}\\n\"\n",
    "            f\"Sección {item.get('seccion_num', '')}: {item.get('seccion_nom', '')}\\n\"\n",
    "            f\"Artículo {item.get('art_num', '')}: {item.get('nombre_juridico', '')}\\n\"\n",
    "            f\"{item.get('contenido', '')}\"\n",
    "        )\n",
    "        \n",
    "    elif tipo == \"Disposición\":\n",
    "        text = (\n",
    "            f\"Disposición {item.get('disposicion', '')}\\n\"\n",
    "            f\"Nombre jurídico: {item.get('nombre_juridico', '')}\\n\"\n",
    "            f\"{item.get('contenido', '')}\"\n",
    "        )\n",
    "\n",
    "    # Pongo este else, porque sino me sale error en page_content=text, porque es posible que text este vacio\n",
    "    else:\n",
    "        text = item.get(\"contenido\", \"\")\n",
    "\n",
    "    docs.append(Document(page_content=text, metadata={\"tipo\": tipo}))\n",
    "\n",
    "print(f\"Se cargaron {len(docs)} documentos desde el JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fa9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  381\n",
      "page_content='Parte Cuarta: Estructura y organización económica del Estado\n",
      "Título 2: Medio Ambiente, Recursos Naturales, Tierra y Territorio\n",
      "Capítulo Séptimo: Biodiversidad, coca, áreas protegidas y recursos forestales\n",
      "Sección 1: Biodiversidad\n",
      "Artículo 380: Aprovechamiento Sustentable de los Recursos Naturales Renovables y Garantía del Equilibrio Ecológico\n",
      "I. Los recursos naturales renovables se aprovecharán de manera sustentable, respetando las características y el valor natural de cada ecosistema. II. Para garantizar el equilibrio ecológico, los suelos deberán utilizarse conforme con su capacidad de uso mayor en el marco del proceso de organización del uso y ocupación del espacio, considerando sus características biofísicas, socioeconómicas, culturales y político institucionales. La ley regulará su aplicación.' metadata={'tipo': 'Articulo'}\n"
     ]
    }
   ],
   "source": [
    "# Solamente para testear que se hayan cargado los documentos correctamente, agarramos uno aleatorio y lo analizamos\n",
    "import random\n",
    "random_document_id = random.choice(range(len(docs)))\n",
    "\n",
    "print(\"test: \", random_document_id)\n",
    "print(docs[random_document_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a4673",
   "metadata": {},
   "source": [
    "## Asignamiento de IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11942a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "metas = []\n",
    "cont = 0\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    if (i<2):\n",
    "        ids.append(f\"introduccion_{i+1}\")\n",
    "        metas.append({\"tipo\": \"introduccion\", \"número\": i+1})\n",
    "    elif(i<399):\n",
    "        ids.append(f\"artículo_{i-1}\")\n",
    "        metas.append({\"tipo\": \"artículo\", \"número\": i-1})\n",
    "    elif(i==399):\n",
    "        ids.append(f\"artículo_398_A\")\n",
    "        metas.append({\"tipo\": \"artículo\", \"número\": \"398_A\"})\n",
    "    elif(i==400):\n",
    "        ids.append(f\"artículo_398_B\")\n",
    "        metas.append({\"tipo\": \"artículo\", \"número\": \"398_B\"})\n",
    "    elif(i<414):\n",
    "        ids.append(f\"artículo_{i-2}\")\n",
    "        metas.append({\"tipo\": \"artículo\", \"número\": i-2})\n",
    "    else:\n",
    "        cont += 1\n",
    "        ids.append(f\"disposición_{cont}\")\n",
    "        metas.append({\"tipo\": \"disposicion\", \"número\": cont})\n",
    "\n",
    "assert len(docs) == len(ids) == len(metas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54b279",
   "metadata": {},
   "source": [
    "# Embedding part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4410687",
   "metadata": {},
   "source": [
    "### Gemini embedding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8d67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction:\n",
    "    def __init__(self, model=\"gemini-embedding-001\"):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, input):\n",
    "        result = gemini_client.models.embed_content(\n",
    "            model=self.model,\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=\"retrieval_document\")\n",
    "        )\n",
    "        return [emb.values for emb in result.embeddings]\n",
    "    \n",
    "    def embed_query(self, input):\n",
    "        result = gemini_client.models.embed_content(\n",
    "            model=self.model,\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=\"retrieval_query\")\n",
    "        )\n",
    "        return [emb.values for emb in result.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571ad61",
   "metadata": {},
   "source": [
    "### Create chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b121f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para crear la base de datos vectorial (Caso de no tener limite de batch)\n",
    "def create_chroma_db(documents, ids, name):\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "    db.add(\n",
    "        documents=[d.page_content for d in documents],\n",
    "        ids=ids\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para crear la base de datos vectorial con batch limitado (no es limite de API)\n",
    "def create_chroma_db(documents, ids, name, batch_size=100):\n",
    "    import time\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./vector/\" + name)\n",
    "\n",
    "    db = chroma_client.create_collection(\n",
    "        name=name,\n",
    "        embedding_function=GeminiEmbeddingFunction()\n",
    "    )\n",
    "\n",
    "    print(f\"Insertando {len(documents)} documentos en lotes de {batch_size}...\")\n",
    "\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch_docs = documents[i:i+batch_size]\n",
    "        batch_ids = ids[i:i+batch_size]\n",
    "\n",
    "        db.add(\n",
    "            documents=[d.page_content for d in batch_docs],\n",
    "            ids=batch_ids\n",
    "        )\n",
    "\n",
    "        print(f\"Lote {i//batch_size + 1} insertado ({len(batch_docs)} docs)\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    print(\"Base de datos creada exitosamente\")\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_chroma_db(docs, ids, \"cpep_gemini_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_data = db.get(include=['documents', 'embeddings'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"IDs\": sample_data['ids'][:15],\n",
    "    \"Documents\": sample_data['documents'][:15],\n",
    "    \"Embeddings\": [str(emb)[:150] + \"...\" for emb in sample_data['embeddings'][:15]]  # Truncate embeddings\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ec8c3",
   "metadata": {},
   "source": [
    "### Cargar chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0323589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos: 426\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path=\"./vector/cpep_gemini_test\")\n",
    "\n",
    "db = client.get_collection(name=\"cpep_gemini_test\")\n",
    "\n",
    "db._embedding_function = GeminiEmbeddingFunction()\n",
    "\n",
    "print(\"Total de documentos:\", db.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed936ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿Qué dice el artículo 398 de la constitución política del estado boliviano?\"\n",
    "results = db.query(query_texts=[query], n_results=5)\n",
    "\n",
    "for i, doc in enumerate(results[\"documents\"][0]):\n",
    "    print(f\"Documento {i+1}\")\n",
    "    print(doc[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea1a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vector_store:\", db.count(), \"documentos.\")\n",
    "print(db.count())\n",
    "print(db.peek())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f1161",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788d09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def print_documents_distances(results, show_score=False):\n",
    "    if show_score:\n",
    "        for i, (doc, score) in enumerate(zip(results[\"documents\"][0], results[\"distances\"][0])):\n",
    "            print(f\"{'-'*80}\")\n",
    "            print(f\"Documento {i+1} | score={round(score, 4)}\")\n",
    "            print(doc[:400])\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        for i, doc in enumerate(results[\"documents\"][0]):\n",
    "            print(f\"{'-'*80}\")\n",
    "            print(f\"Documento {i+1}\")\n",
    "            print(doc[:400])\n",
    "            print(\"\\n\")\n",
    "\n",
    "def print_documents_similarity(results, show_score=False):\n",
    "    if show_score:\n",
    "        for i, (doc, dist) in enumerate(zip(results[\"documents\"][0], results[\"distances\"][0])):\n",
    "            similarity = 1 - dist  # convertir distancia a similitud\n",
    "            print(f\"{'-'*80}\")\n",
    "            print(f\"Documento {i+1} | similitud={round(similarity,4)}\")\n",
    "            print(doc[:400])\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        for i, doc in enumerate(results[\"documents\"][0]):\n",
    "            print(f\"{'-'*80}\")\n",
    "            print(f\"Documento {i+1}\")\n",
    "            print(doc[:400])\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"¿Qué dice el artículo 398 de la constitución política del estado boliviano?\"\n",
    "results = db.query(query_texts=[query], n_results=5)\n",
    "print_documents_distances(results, show_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_documents_similarity(results, show_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b40c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_adapter = GeminiEmbeddingFunction()\n",
    "query_embeddings = embedding_adapter.embed_query(query)[0]\n",
    "\n",
    "docs_texts = results[\"documents\"][0]\n",
    "\n",
    "docs_embeddings = [embedding_adapter(text)[0] for text in docs_texts]\n",
    "\n",
    "for i, doc_emb in enumerate(docs_embeddings):\n",
    "    similarity = np.dot(query_embeddings, doc_emb) / (\n",
    "        np.linalg.norm(query_embeddings) * np.linalg.norm(doc_emb)\n",
    "    )\n",
    "    print(f\"Similaridad de documento_{i+1} con el query: {round(similarity,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595926e",
   "metadata": {},
   "source": [
    "# Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874848ac",
   "metadata": {},
   "source": [
    "### Vector Store-backed retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab66ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ChromaGeminiRetriever:\n",
    "    def __init__(self, chroma_collection, embedding_function, k=4, score_threshold=None):\n",
    "        self.collection = chroma_collection\n",
    "        self.embedding_function = embedding_function\n",
    "        self.k = k\n",
    "        self.score_threshold = score_threshold\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        results = self.collection.query(query_texts=[query], n_results=self.k)\n",
    "\n",
    "        if self.score_threshold is not None and \"distances\" in results:\n",
    "            filtered_docs = []\n",
    "            filtered_scores = []\n",
    "            for doc, score in zip(results[\"documents\"][0], results[\"distances\"][0]):\n",
    "                if score <= self.score_threshold:\n",
    "                    filtered_docs.append(doc)\n",
    "                    filtered_scores.append(score)\n",
    "            results[\"documents\"][0] = filtered_docs\n",
    "            results[\"distances\"][0] = filtered_scores\n",
    "\n",
    "        return results\n",
    "\n",
    "    def invoke(self, query):\n",
    "        return self.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "344bec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = GeminiEmbeddingFunction()\n",
    "retriever_gemini = ChromaGeminiRetriever(\n",
    "    chroma_collection=db,\n",
    "    embedding_function=embedding_function,\n",
    "    k=5,                      \n",
    "    score_threshold=None     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿Qué dice el artículo 398 de la constitución política del estado boliviano?\"\n",
    "relevant_docs = retriever_gemini.invoke(query)\n",
    "print_documents_similarity(relevant_docs, show_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de44845",
   "metadata": {},
   "source": [
    "### ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4270d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGemini:\n",
    "    def __init__(self, model=\"gemini-2.5-flash-lite\", temperature=0.3, memory=None):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.memory = memory\n",
    "\n",
    "    def invoke(self, prompt):\n",
    "        # Incluir memoria\n",
    "        if self.memory and self.memory.history:\n",
    "            context = self.memory.get_context()\n",
    "            prompt = f\"{context}\\n\\nUsuario: {prompt}\\nAsistente:\"\n",
    "        \n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"temperature\": self.temperature,\n",
    "                \"max_output_tokens\": 1024\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if self.memory:\n",
    "            self.memory.add_message(\"user\", prompt)\n",
    "            self.memory.add_message(\"assistant\", response.text)\n",
    "\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8db0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGemini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd308537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "prompt_test = \"¿Qué dice el artículo 398 de la Constitución Política del estado boliviano?\"\n",
    "response = llm.invoke(prompt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9379c",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657fb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class ConversationMemory:\n",
    "    def __init__(self, max_turns=10):\n",
    "        self.history = []\n",
    "        self.max_turns = max_turns\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        # Agregar el mensaje al historial user o assistant\n",
    "        self.history.append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "        if len(self.history) > self.max_turns * 2:\n",
    "            self.history = self.history[-self.max_turns*2:]\n",
    "\n",
    "    def get_context(self):\n",
    "        if not self.history:\n",
    "            return \"No hay historial previo.\"\n",
    "        return \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in self.history])\n",
    "\n",
    "    def clear(self):\n",
    "        self.history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d303d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_chat_session(llm):\n",
    "    if llm.memory:\n",
    "        llm.memory.clear()\n",
    "        print(\" Memoria temporal del chat borrada.\")\n",
    "    else:\n",
    "        print(\"No hay memoria activa para borrar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70268bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para resetear la memoria\n",
    "reset_chat_session(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6dc45",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c062651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standalone_question_template = \"\"\"\n",
    "Dada la siguiente conversación y una pregunta de seguimiento,\n",
    "reformula la pregunta de seguimiento para que sea una pregunta independiente,\n",
    "manteniendo su significado original y en el mismo idioma (español).\n",
    "\n",
    "Historial de chat:\n",
    "{chat_history}\n",
    "\n",
    "Pregunta de seguimiento:\n",
    "{question}\n",
    "\n",
    "Pregunta independiente:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5697e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reformulation_prompt(memory, question):\n",
    "    chat_history = memory.get_context() if memory else \"No hay historial previo.\"\n",
    "    prompt = standalone_question_template.format(\n",
    "        chat_history=chat_history,\n",
    "        question=question\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82189f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n",
    "memory = ConversationMemory(max_turns=5)\n",
    "\n",
    "memory.add_message(\"user\", \"¿Qué dice el artículo 7 de la Constitución Política del Estado boliviano?\")\n",
    "memory.add_message(\"assistant\", \"El Artículo 7 establece los principios fundamentales del Estado Plurinacional de Bolivia.\")\n",
    "\n",
    "nueva_pregunta = \"¿Y qué pasa si no se respetan esos derechos?\"\n",
    "\n",
    "prompt_reformulado = build_reformulation_prompt(memory, nueva_pregunta)\n",
    "print(prompt_reformulado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta_reformulada = llm.invoke(prompt_reformulado)\n",
    "print(respuesta_reformulada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b7636",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "511927b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_template(language=\"spanish\"):\n",
    "    template = f\"\"\"Eres un asistente especializado en la Constitución Política del Estado Plurinacional de Bolivia.\n",
    "Responde la siguiente pregunta utilizando únicamente la información proporcionada en el contexto (delimitado por <context>).\n",
    "Tu respuesta debe estar en el idioma del final y debes aclarar que artículos, disposiciones o textos usaste para escribir la respuesta.\n",
    "\n",
    "Si la información no es suficiente o no se encuentra en el contexto, responde claramente:\n",
    "\"No tengo información suficiente en la Constitución para responder a esta pregunta.\"\n",
    "\n",
    "<context>\n",
    "{{context}}\n",
    "</context>\n",
    "\n",
    "Pregunta: {{question}}\n",
    "\n",
    "Idioma: {language}.\n",
    "\"\"\"\n",
    "    return template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e2fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_answer_prompt(memory, context, question, language=\"Spanish\"):\n",
    "    chat_template = answer_template(language=language)\n",
    "    chat_history = memory.get_context() if memory else \"No hay historial previo.\"\n",
    "\n",
    "    prompt = chat_template.format(\n",
    "        context=context,\n",
    "        chat_history=chat_history,\n",
    "        question=question\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a262cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationMemory(max_turns=5)\n",
    "memory.add_message(\"user\", \"¿Qué dice el artículo 7 de la Constitución?\")\n",
    "memory.add_message(\"assistant\", \"El Artículo 7 establece los principios fundamentales del Estado boliviano.\")\n",
    "\n",
    "pregunta_final = \"¿Qué sucede si no se respetan los derechos fundamentales establecidos en el artículo 7?\"\n",
    "\n",
    "resultados = retriever_gemini.invoke(pregunta_final)\n",
    "contexto = \"\\n\".join(resultados[\"documents\"][0])\n",
    "prompt_final = build_answer_prompt(memory, contexto, pregunta_final, language=\"Spanish\")\n",
    "print(prompt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = llm.invoke(prompt_final)\n",
    "print(respuesta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d342e0d",
   "metadata": {},
   "source": [
    "# Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf29b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalRAG:\n",
    "    def __init__(self, llm, retriever, memory, question_template, answer_template):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.memory = memory\n",
    "        self.question_template = question_template\n",
    "        self.answer_template = answer_template\n",
    "\n",
    "    def reformulate_question(self, question):\n",
    "        chat_history = self.memory.get_context()\n",
    "        prompt = self.question_template.format(\n",
    "            chat_history=chat_history,\n",
    "            question=question\n",
    "        )\n",
    "        new_question = self.llm.invoke(prompt)\n",
    "        return new_question\n",
    "\n",
    "    def retrieve_context(self, query):\n",
    "        results = self.retriever.invoke(query)\n",
    "        context = \"\\n\".join(results[\"documents\"][0])\n",
    "        return context\n",
    "    \n",
    "    def generate_answer(self, question, context):\n",
    "        chat_history = self.memory.get_context()\n",
    "        prompt = self.answer_template.format(\n",
    "            context=context,\n",
    "            chat_history=chat_history,\n",
    "            question=question\n",
    "        )\n",
    "        answer = self.llm.invoke(prompt)\n",
    "        return answer\n",
    "\n",
    "    def invoke(self, question):\n",
    "        condensed_q = self.reformulate_question(question)\n",
    "        print(f\"Pregunta reformulada: {condensed_q}\")\n",
    "\n",
    "        context = self.retrieve_context(condensed_q)\n",
    "\n",
    "        answer = self.generate_answer(condensed_q, context)\n",
    "\n",
    "        self.memory.add_message(\"user\", question)\n",
    "        self.memory.add_message(\"assistant\", answer)\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"context\": context,\n",
    "            \"reformulated\": condensed_q\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85671869",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationMemory(max_turns=5)\n",
    "retriever = retriever_gemini\n",
    "question_template = standalone_question_template\n",
    "chat_chain = ConversationalRAG(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    question_template=question_template,\n",
    "    answer_template=answer_template(language=\"Spanish\")  \n",
    ")\n",
    "response1 = chat_chain.invoke(\"\")\n",
    "print(response1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chat_chain.invoke(\"\")\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chat_chain.invoke(\"¿Y cuanto es la raiz cuadrada de 16?\")\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a56fa0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmemory\u001b[49m.clear()\n",
      "\u001b[31mNameError\u001b[39m: name 'memory' is not defined"
     ]
    }
   ],
   "source": [
    "memory.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
